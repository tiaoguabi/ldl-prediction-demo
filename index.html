<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>LDL Prediction</title>
  <!-- Load ONNX Runtime Web so that `ort` is defined -->
  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@latest/dist/ort.min.js"></script>
</head>
<body>
  <h1>LDL Prediction Model</h1>
  <form id="inputForm">
    <label for="tc">Total Cholesterol:</label>
    <input type="number" id="tc" required /><br /><br />

    <label for="tg">Triglycerides:</label>
    <input type="number" id="tg" required /><br /><br />

    <label for="hdl">HDL Cholesterol:</label>
    <input type="number" id="hdl" required /><br /><br />

    <button type="submit">Predict LDL</button>
  </form>

  <h2>Predicted LDL: <span id="result">-</span></h2>

  <script>
    // Point to the ONNX Runtime WebAssembly assets
    ort.env.wasm.wasmPaths = 'https://cdn.jsdelivr.net/npm/onnxruntime-web@latest/dist/';

    // Load the ONNX model from GitHub Raw URL
    async function loadModel() {
      return await ort.InferenceSession.create(
        'https://raw.githubusercontent.com/tiaoguabi/ldl-prediction-demo/main/ebm_model.onnx'
      );
    }

    async function predict(event) {
      event.preventDefault();

      // Read numeric values from the form
      const tc = parseFloat(document.getElementById('tc').value);
      const tg = parseFloat(document.getElementById('tg').value);
      const hdl = parseFloat(document.getElementById('hdl').value);

      // Load the model session
      const session = await loadModel();

      // Log the model's actual input names for verification
      console.log('Model expects inputs:', session.inputNames);

      // Construct feeds exactly like Python's list-based input_data2
      const feeds = {
        // Each feature must be wrapped in an array of length 1
        [session.inputNames[0]]: new ort.Tensor('float32', new Float32Array([tc]), [1]),
        [session.inputNames[1]]: new ort.Tensor('float32', new Float32Array([tg]), [1]),
        [session.inputNames[2]]: new ort.Tensor('float32', new Float32Array([hdl]), [1]),
      };

      // Run inference
      const results = await session.run(feeds);

      // Get the first (and only) output name
      const outputName = session.outputNames[0];

      // Extract the single prediction value
      const prediction = results[outputName].data[0];

      // Display the result rounded to two decimals
      document.getElementById('result').innerText = prediction.toFixed(2);
    }

    // Attach the predict function to form submission
    document.getElementById('inputForm').addEventListener('submit', predict);
  </script>
</body>
</html>
