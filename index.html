<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>LDL Prediction Demo</title>
  <!-- Load ONNX Runtime Web to expose the global `ort` object -->
  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@latest/dist/ort.min.js"></script>
</head>
<body>
  <h1>LDL Prediction Model</h1>
  <form id="inputForm">
    <label for="tc">Total Cholesterol (TC) (mg/dL):</label>
    <input type="number" id="tc" required /><br /><br />

    <label for="tg">Triglycerides (TG) (mg/dL):</label>
    <input type="number" id="tg" required /><br /><br />

    <label for="hdl">HDL Cholesterol (mg/dL):</label>
    <input type="number" id="hdl" required /><br /><br />

    <button type="submit">Predict LDL</button>
  </form>

  <h2>Predicted LDL: <span id="result">-</span></h2>

  <script>
    // Specify path to WASM assets for ONNX Runtime Web
    ort.env.wasm.wasmPaths = 'https://cdn.jsdelivr.net/npm/onnxruntime-web@latest/dist/';

    // Load the ONNX model from GitHub Raw URL
    async function loadModel() {
      return await ort.InferenceSession.create(
        'https://raw.githubusercontent.com/tiaoguabi/ldl-prediction-demo/main/ebm_model.onnx'
      );
    }

    // Handle form submission and run inference
    async function predict(event) {
      event.preventDefault();

      // Parse numeric inputs from the form
      const tc = parseFloat(document.getElementById('tc').value);
      const tg = parseFloat(document.getElementById('tg').value);
      const hdl = parseFloat(document.getElementById('hdl').value);

      // Create a session for inference
      const session = await loadModel();

      // Construct feeds matching Python's list-based input_data2
      const feeds = {
        [session.inputNames[0]]: new ort.Tensor('float64', new Float64Array([tc]), [1]),
        [session.inputNames[1]]: new ort.Tensor('float64', new Float64Array([hdl]), [1]),
        [session.inputNames[2]]: new ort.Tensor('float64', new Float64Array([tg]), [1]),
      };

      // Run the model
      const results = await session.run(feeds);

      // Extract prediction from the first output
      const outputName = session.outputNames[0];
      const prediction = results[outputName].data[0];

      // Display the result rounded to two decimal places
      document.getElementById('result').innerText = prediction.toFixed(2);
    }

    // Bind the predict function to the form submit event
    document.getElementById('inputForm').addEventListener('submit', predict);
  </script>
</body>
</html>
