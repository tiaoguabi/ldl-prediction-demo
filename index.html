<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>LDL Prediction</title>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@latest/dist/ort.min.js"></script>
</head>
<body>
    <h1>LDL Prediction Model</h1>
    <form id="inputForm">
        <label for="tc">Total Cholesterol (TC):</label>
        <input type="number" id="tc" required><br><br>

        <label for="tg">Triglycerides (TG):</label>
        <input type="number" id="tg" required><br><br>

        <label for="hdl">HDL Cholesterol:</label>
        <input type="number" id="hdl" required><br><br>

        <button type="submit">Predict LDL</button>
    </form>

    <h2>Predicted LDL: <span id="result">-</span></h2>

    <script>
        ort.env.wasm.wasmPaths = 'https://cdn.jsdelivr.net/npm/onnxruntime-web@latest/dist/';

        async function loadModel() {
            const session = await ort.InferenceSession.create('https://raw.githubusercontent.com/tiaoguabi/ldl-prediction-demo/main/ebm_model.onnx');
            return session;
        }

        async function predict(event) {
            event.preventDefault();
            const tc = parseFloat(document.getElementById('tc').value);
            const tg = parseFloat(document.getElementById('tg').value);
            const hdl = parseFloat(document.getElementById('hdl').value);

            const inputData = new ort.Tensor('float32', new Float32Array([tc, tg, hdl]), [1, 3]);

            const session = await loadModel();
            const feeds = {};
            feeds[session.inputNames[0]] = inputData;

            const output = await session.run(feeds);
            const outputName = session.outputNames[0];
            const prediction = output[outputName].data[0];

            document.getElementById('result').innerText = prediction.toFixed(2);
        }

        document.getElementById('inputForm').addEventListener('submit', predict);
    </script>
</body>
</html>
